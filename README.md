# ğŸŒ¼ Iris Neural Network: From Scratch vs. PyTorch

This project showcases how to build a neural network **from scratch using NumPy** and compare it with an equivalent model implemented using **PyTorch**. The focus is on **learning**, **understanding**, and **visualizing** how neural networks learn to classify real-world data.

I used the Iris dataset, which is a classic multi-class classification problem involving three flower species.

---

## ğŸ“š Overview

- ğŸ§  Manual Neural Network built with NumPy
- âš™ï¸ Equivalent model built using PyTorch
- ğŸ“‰ Loss curves for both models
- ğŸ¯ Prediction visualization and comparison
- ğŸŒˆ Decision boundary plot to show model behavior

---

## ğŸ—‚ï¸ Project Structure

â”œâ”€â”€ iris_nn.py # NumPy implementation
â”œâ”€â”€ iris_nn_pytorch.py # PyTorch implementation
â”œâ”€â”€ plot_decision_boundaries.py # For visualization
â”œâ”€â”€ iris_nn_comparisonIris Neural Metwork From Scratch to PyTorch.ipynb # Jupyter notebook version
â”œâ”€â”€ loss_manual.npy # Saved manual loss curve
â”œâ”€â”€ loss_pytorch.npy # Saved PyTorch loss curve
â”œâ”€â”€ plot_loses.png #  Combined loss plot
â”œâ”€â”€ plot_des_bon.png # Decision boundary plot
â”œâ”€â”€ scratch_predictions.npy # Predictions by manual model
â”œâ”€â”€ pytorch_predictions.npy # Predictions by PyTorch model
â”œâ”€â”€ torch_model.pth # Serialized PyTorch model state
â””â”€â”€ README.md

---

## ğŸŒ¸ The Iris Dataset

- **Features**:  
  - Sepal length  
  - Sepal width  
  - Petal length  
  - Petal width  
- **Classes**:  
  - Setosa  
  - Versicolor  
  - Virginica

---

## ğŸ”§ Neural Network Architectures

### âœ… NumPy (From Scratch)
- 4 input neurons â†’ 6 hidden (ReLU) â†’ 3 output (Softmax)
- Manual implementation of forward/backward propagation
- Cross-entropy loss and basic gradient descent

### âš¡ PyTorch
- Same architecture using `torch.nn.Linear`
- Uses ReLU activations, softmax, and `torch.optim.Adam`
- Faster training and optimized performance

---

## ğŸ“ˆ Training Performance

### ğŸ§ª Loss Curves

![Loss Plot](plot_loses.png)

Both models successfully minimize the loss. PyTorch converges more quickly due to advanced optimizers, while the manual model shows a steady decline, proving the custom backpropagation logic works.

---

### ğŸ§  Decision Boundary

![Decision Boundary](plot_des_bon.png)

The decision boundary visualizes how each model separates classes using only two selected features. Both models show strong generalization and class separation.

---

## ğŸš€ Running the Project

### âœ… Dependencies

- Python 3.8+
- NumPy
- Matplotlib
- scikit-learn
- PyTorch
- Jupyter Notebook (optional)

### ğŸ› ï¸ Setup

```bash
pip install numpy matplotlib scikit-learn torch notebook

```
#### â–¶ï¸ Steps

- Train the from-scratch model

```bash
python iris_nn.py

```
- Train the PyTorch model

```bash
python iris_nn_pytprch.py

```

- Generate plots

```bash 

python plot_decision_boundaries.py

```

- Explore in Jupyter Notebook

```bash 

jupyter notebook Iris Neural Network From Scratch to PyTorch.ipynb

```
---

## ğŸ’¡ Key Learnings

- How neural networks work under the hood

- Manual backpropagation and gradient updates

- Benefits of using deep learning frameworks like PyTorch

- Visualizing predictions and decision boundaries

---

## ğŸ‘¤ Author

[M26I](https://github.com/M26I)
---
Â© 2025 M26I â€“ For educational/portfolio use only.  
Unauthorized use or redistribution without credit is prohibited.
